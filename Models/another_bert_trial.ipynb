{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "972c60d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "\n",
    "# Torch ML libraries\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Misc.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd4133de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1535, 13)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_df_2.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be9d0fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RID</th>\n",
       "      <th>SID</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "      <th>aspect_term</th>\n",
       "      <th>aspect_category</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>text_word</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000:0</td>\n",
       "      <td>Manzara sahane evet ama servis rezalet.</td>\n",
       "      <td>negative</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>servis</td>\n",
       "      <td>SERVICE</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>manzara sahane evet servis rezalet</td>\n",
       "      <td>['manzara', 'sahane', 'evet', 'servis', 'rezal...</td>\n",
       "      <td>5</td>\n",
       "      <td>manzara sahane evet servis rezalet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000:0</td>\n",
       "      <td>Manzara sahane evet ama servis rezalet.</td>\n",
       "      <td>positive</td>\n",
       "      <td>AMBIENCE#GENERAL</td>\n",
       "      <td>Manzara</td>\n",
       "      <td>AMBIENCE</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>manzara sahane evet servis rezalet</td>\n",
       "      <td>['manzara', 'sahane', 'evet', 'servis', 'rezal...</td>\n",
       "      <td>5</td>\n",
       "      <td>manzara sahane evet servis rezalet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000:1</td>\n",
       "      <td>Soguk su isteyince, soguk yok, butun sulari di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>FOOD#STYLE_OPTIONS</td>\n",
       "      <td>mezenin</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>STYLE_OPTIONS</td>\n",
       "      <td>soguk su isteyince soguk yok butun sulari disa...</td>\n",
       "      <td>['soguk', 'su', 'isteyince', 'soguk', 'yok', '...</td>\n",
       "      <td>26</td>\n",
       "      <td>soguk su istemek soguk yok butun sulari disari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000:1</td>\n",
       "      <td>Soguk su isteyince, soguk yok, butun sulari di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>garson</td>\n",
       "      <td>SERVICE</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>soguk su isteyince soguk yok butun sulari disa...</td>\n",
       "      <td>['soguk', 'su', 'isteyince', 'soguk', 'yok', '...</td>\n",
       "      <td>26</td>\n",
       "      <td>soguk su istemek soguk yok butun sulari disari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000:2</td>\n",
       "      <td>Yemekler iyi hos, lezzetler iyi ama heyecan ve...</td>\n",
       "      <td>positive</td>\n",
       "      <td>FOOD#QUALITY</td>\n",
       "      <td>lezzetler</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>QUALITY</td>\n",
       "      <td>yemekler iyi hos lezzetler iyi heyecan verici ...</td>\n",
       "      <td>['yemekler', 'iyi', 'hos', 'lezzetler', 'iyi',...</td>\n",
       "      <td>21</td>\n",
       "      <td>yemek iyi hos lezzet iyi heyecan veri bi taraf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   RID     SID  \\\n",
       "0           0  1000  1000:0   \n",
       "1           1  1000  1000:0   \n",
       "2           2  1000  1000:1   \n",
       "3           3  1000  1000:1   \n",
       "4           4  1000  1000:2   \n",
       "\n",
       "                                                text  polarity  \\\n",
       "0            Manzara sahane evet ama servis rezalet.  negative   \n",
       "1            Manzara sahane evet ama servis rezalet.  positive   \n",
       "2  Soguk su isteyince, soguk yok, butun sulari di...  negative   \n",
       "3  Soguk su isteyince, soguk yok, butun sulari di...  negative   \n",
       "4  Yemekler iyi hos, lezzetler iyi ama heyecan ve...  positive   \n",
       "\n",
       "             category     target aspect_term aspect_category  \\\n",
       "0     SERVICE#GENERAL     servis     SERVICE         GENERAL   \n",
       "1    AMBIENCE#GENERAL    Manzara    AMBIENCE         GENERAL   \n",
       "2  FOOD#STYLE_OPTIONS    mezenin        FOOD   STYLE_OPTIONS   \n",
       "3     SERVICE#GENERAL     garson     SERVICE         GENERAL   \n",
       "4        FOOD#QUALITY  lezzetler        FOOD         QUALITY   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0                 manzara sahane evet servis rezalet   \n",
       "1                 manzara sahane evet servis rezalet   \n",
       "2  soguk su isteyince soguk yok butun sulari disa...   \n",
       "3  soguk su isteyince soguk yok butun sulari disa...   \n",
       "4  yemekler iyi hos lezzetler iyi heyecan verici ...   \n",
       "\n",
       "                                           text_word  text_word_count  \\\n",
       "0  ['manzara', 'sahane', 'evet', 'servis', 'rezal...                5   \n",
       "1  ['manzara', 'sahane', 'evet', 'servis', 'rezal...                5   \n",
       "2  ['soguk', 'su', 'isteyince', 'soguk', 'yok', '...               26   \n",
       "3  ['soguk', 'su', 'isteyince', 'soguk', 'yok', '...               26   \n",
       "4  ['yemekler', 'iyi', 'hos', 'lezzetler', 'iyi',...               21   \n",
       "\n",
       "                                          lemmatized  \n",
       "0                 manzara sahane evet servis rezalet  \n",
       "1                 manzara sahane evet servis rezalet  \n",
       "2  soguk su istemek soguk yok butun sulari disari...  \n",
       "3  soguk su istemek soguk yok butun sulari disari...  \n",
       "4  yemek iyi hos lezzet iyi heyecan veri bi taraf...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look at the data \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23506f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RID</th>\n",
       "      <th>SID</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "      <th>aspect_term</th>\n",
       "      <th>aspect_category</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>text_word</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>category_cat</th>\n",
       "      <th>polarity_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000:0</td>\n",
       "      <td>Manzara sahane evet ama servis rezalet.</td>\n",
       "      <td>negative</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>servis</td>\n",
       "      <td>SERVICE</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>manzara sahane evet servis rezalet</td>\n",
       "      <td>['manzara', 'sahane', 'evet', 'servis', 'rezal...</td>\n",
       "      <td>5</td>\n",
       "      <td>manzara sahane evet servis rezalet</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000:0</td>\n",
       "      <td>Manzara sahane evet ama servis rezalet.</td>\n",
       "      <td>positive</td>\n",
       "      <td>AMBIENCE#GENERAL</td>\n",
       "      <td>Manzara</td>\n",
       "      <td>AMBIENCE</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>manzara sahane evet servis rezalet</td>\n",
       "      <td>['manzara', 'sahane', 'evet', 'servis', 'rezal...</td>\n",
       "      <td>5</td>\n",
       "      <td>manzara sahane evet servis rezalet</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000:1</td>\n",
       "      <td>Soguk su isteyince, soguk yok, butun sulari di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>FOOD#STYLE_OPTIONS</td>\n",
       "      <td>mezenin</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>STYLE_OPTIONS</td>\n",
       "      <td>soguk su isteyince soguk yok butun sulari disa...</td>\n",
       "      <td>['soguk', 'su', 'isteyince', 'soguk', 'yok', '...</td>\n",
       "      <td>26</td>\n",
       "      <td>soguk su istemek soguk yok butun sulari disari...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000:1</td>\n",
       "      <td>Soguk su isteyince, soguk yok, butun sulari di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>garson</td>\n",
       "      <td>SERVICE</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>soguk su isteyince soguk yok butun sulari disa...</td>\n",
       "      <td>['soguk', 'su', 'isteyince', 'soguk', 'yok', '...</td>\n",
       "      <td>26</td>\n",
       "      <td>soguk su istemek soguk yok butun sulari disari...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000:2</td>\n",
       "      <td>Yemekler iyi hos, lezzetler iyi ama heyecan ve...</td>\n",
       "      <td>positive</td>\n",
       "      <td>FOOD#QUALITY</td>\n",
       "      <td>lezzetler</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>QUALITY</td>\n",
       "      <td>yemekler iyi hos lezzetler iyi heyecan verici ...</td>\n",
       "      <td>['yemekler', 'iyi', 'hos', 'lezzetler', 'iyi',...</td>\n",
       "      <td>21</td>\n",
       "      <td>yemek iyi hos lezzet iyi heyecan veri bi taraf...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   RID     SID  \\\n",
       "0           0  1000  1000:0   \n",
       "1           1  1000  1000:0   \n",
       "2           2  1000  1000:1   \n",
       "3           3  1000  1000:1   \n",
       "4           4  1000  1000:2   \n",
       "\n",
       "                                                text  polarity  \\\n",
       "0            Manzara sahane evet ama servis rezalet.  negative   \n",
       "1            Manzara sahane evet ama servis rezalet.  positive   \n",
       "2  Soguk su isteyince, soguk yok, butun sulari di...  negative   \n",
       "3  Soguk su isteyince, soguk yok, butun sulari di...  negative   \n",
       "4  Yemekler iyi hos, lezzetler iyi ama heyecan ve...  positive   \n",
       "\n",
       "             category     target aspect_term aspect_category  \\\n",
       "0     SERVICE#GENERAL     servis     SERVICE         GENERAL   \n",
       "1    AMBIENCE#GENERAL    Manzara    AMBIENCE         GENERAL   \n",
       "2  FOOD#STYLE_OPTIONS    mezenin        FOOD   STYLE_OPTIONS   \n",
       "3     SERVICE#GENERAL     garson     SERVICE         GENERAL   \n",
       "4        FOOD#QUALITY  lezzetler        FOOD         QUALITY   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0                 manzara sahane evet servis rezalet   \n",
       "1                 manzara sahane evet servis rezalet   \n",
       "2  soguk su isteyince soguk yok butun sulari disa...   \n",
       "3  soguk su isteyince soguk yok butun sulari disa...   \n",
       "4  yemekler iyi hos lezzetler iyi heyecan verici ...   \n",
       "\n",
       "                                           text_word  text_word_count  \\\n",
       "0  ['manzara', 'sahane', 'evet', 'servis', 'rezal...                5   \n",
       "1  ['manzara', 'sahane', 'evet', 'servis', 'rezal...                5   \n",
       "2  ['soguk', 'su', 'isteyince', 'soguk', 'yok', '...               26   \n",
       "3  ['soguk', 'su', 'isteyince', 'soguk', 'yok', '...               26   \n",
       "4  ['yemekler', 'iyi', 'hos', 'lezzetler', 'iyi',...               21   \n",
       "\n",
       "                                          lemmatized  category_cat  \\\n",
       "0                 manzara sahane evet servis rezalet            11   \n",
       "1                 manzara sahane evet servis rezalet             0   \n",
       "2  soguk su istemek soguk yok butun sulari disari...             6   \n",
       "3  soguk su istemek soguk yok butun sulari disari...            11   \n",
       "4  yemek iyi hos lezzet iyi heyecan veri bi taraf...             5   \n",
       "\n",
       "   polarity_cat  \n",
       "0             0  \n",
       "1             2  \n",
       "2             0  \n",
       "3             0  \n",
       "4             2  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aspect encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "df[\"category\"] = df[\"category\"].astype('category')\n",
    "df[\"polarity\"] = df[\"polarity\"].astype('category')\n",
    "\n",
    "df[\"category_cat\"] = df[\"category\"].cat.codes\n",
    "df[\"polarity_cat\"] = df[\"polarity\"].cat.codes\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1efa8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model name\n",
    "MODEL_NAME = 'dbmdz/bert-base-turkish-128k-cased'\n",
    "\n",
    "# Build a BERT based tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e493f2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEP] 3\n",
      "[CLS] 2\n",
      "[PAD] 0\n",
      "[UNK] 1\n"
     ]
    }
   ],
   "source": [
    "# Some of the common BERT tokens\n",
    "print(tokenizer.sep_token, tokenizer.sep_token_id) # marker for ending of a sentence\n",
    "print(tokenizer.cls_token, tokenizer.cls_token_id) # start of each sentence, so BERT knows we’re doing classification\n",
    "print(tokenizer.pad_token, tokenizer.pad_token_id) # special token for padding\n",
    "print(tokenizer.unk_token, tokenizer.unk_token_id) # tokens not found in training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ccdfe37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12495 entries, 0 to 12494\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   reviewId              12495 non-null  object\n",
      " 1   userName              12495 non-null  object\n",
      " 2   userImage             12495 non-null  object\n",
      " 3   content               12495 non-null  object\n",
      " 4   score                 12495 non-null  int64 \n",
      " 5   thumbsUpCount         12495 non-null  int64 \n",
      " 6   reviewCreatedVersion  10333 non-null  object\n",
      " 7   at                    12495 non-null  object\n",
      " 8   replyContent          5818 non-null   object\n",
      " 9   repliedAt             5818 non-null   object\n",
      " 10  sortOrder             12495 non-null  object\n",
      " 11  appId                 12495 non-null  object\n",
      "dtypes: int64(2), object(10)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_2 = pd.read_csv('reviews.csv')\n",
    "df_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e97f635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1535 entries, 0 to 1534\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   Unnamed: 0       1535 non-null   int64   \n",
      " 1   RID              1535 non-null   int64   \n",
      " 2   SID              1535 non-null   object  \n",
      " 3   text             1535 non-null   object  \n",
      " 4   polarity         1535 non-null   category\n",
      " 5   category         1535 non-null   category\n",
      " 6   target           1385 non-null   object  \n",
      " 7   aspect_term      1535 non-null   object  \n",
      " 8   aspect_category  1535 non-null   object  \n",
      " 9   cleaned_text     1533 non-null   object  \n",
      " 10  text_word        1535 non-null   object  \n",
      " 11  text_word_count  1535 non-null   int64   \n",
      " 12  lemmatized       1533 non-null   object  \n",
      " 13  category_cat     1535 non-null   int8    \n",
      " 14  polarity_cat     1535 non-null   int8    \n",
      "dtypes: category(2), int64(3), int8(2), object(8)\n",
      "memory usage: 138.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0af07b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           0\n",
       "RID                  0\n",
       "SID                  0\n",
       "text                 0\n",
       "polarity             0\n",
       "category             0\n",
       "target             148\n",
       "aspect_term          0\n",
       "aspect_category      0\n",
       "cleaned_text         0\n",
       "text_word            0\n",
       "text_word_count      0\n",
       "lemmatized           0\n",
       "category_cat         0\n",
       "polarity_cat         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e77fcd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = [\"lemmatized\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d50f7201",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized'] = df['lemmatized'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25c4e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store length of each review \n",
    "token_lens = []\n",
    "\n",
    "# Iterate through the content slide\n",
    "for txt in df.lemmatized:\n",
    "    tokens = tokenizer.encode(txt, max_length=512)\n",
    "    token_lens.append(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c3af0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Token count')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of review lengths \n",
    "sns.distplot(token_lens)\n",
    "plt.xlim([0, 256]);\n",
    "plt.xlabel('Token count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09df0e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b60ca6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPReviewDataset(Dataset):\n",
    "    # Constructor Function \n",
    "    def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "        self.reviews = reviews\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    # Length magic method\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "    \n",
    "    # get item magic method\n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.reviews[item])\n",
    "        target = self.targets[item]\n",
    "        \n",
    "        # Encoded format to be returned \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'review_text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "02fe74fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1226, 15) (153, 15) (154, 15)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=24)\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=24)\n",
    "\n",
    "print(df_train.shape, df_val.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aadfae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = GPReviewDataset(\n",
    "        reviews=df.lemmatized.to_numpy(),\n",
    "        targets=df.polarity_cat.to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    \n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae60bac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, test and val data loaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "03b515b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Examples \n",
    "data = next(iter(train_data_loader))\n",
    "print(data.keys())\n",
    "\n",
    "print(data['input_ids'].shape)\n",
    "print(data['attention_mask'].shape)\n",
    "print(data['targets'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ece59eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-turkish-128k-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load the basic BERT model \n",
    "bert_model = BertModel.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e5b02b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Sentiment Classifier class \n",
    "class SentimentClassifier(nn.Module):\n",
    "    \n",
    "    # Constructor class \n",
    "    def __init__(self, n_classes):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(MODEL_NAME)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "    \n",
    "    # Forward propagaion class\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(\n",
    "          input_ids=input_ids,\n",
    "          attention_mask=attention_mask\n",
    "        )\n",
    "        #  Add a dropout layer \n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9dc5b6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-turkish-128k-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model and move to classifier\n",
    "model = SentimentClassifier(3)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "62ac7ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "# Number of hidden units\n",
    "print(bert_model.config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "47a61ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations \n",
    "EPOCHS = 10\n",
    "\n",
    "# Optimizer Adam \n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Set the loss function \n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5050505c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for a single training iteration\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Backward prop\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient Descent\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4b22ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "            \n",
    "            # Get model ouptuts\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            \n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ec59f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 1.20 GiB already allocated; 0 bytes free; 1.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:10\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "Input \u001b[1;32mIn [62]\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[0;32m      9\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m targets \u001b[38;5;241m=\u001b[39m d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, targets)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [57]\u001b[0m, in \u001b[0;36mSentimentClassifier.forward\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask):\n\u001b[1;32m---> 13\u001b[0m     _, pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m#  Add a dropout layer \u001b[39;00m\n\u001b[0;32m     18\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(pooled_output)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\bert\\modeling_bert.py:996\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    987\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    989\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m    990\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    991\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    994\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    995\u001b[0m )\n\u001b[1;32m--> 996\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1008\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1009\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\bert\\modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    576\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    577\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    578\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    582\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    583\u001b[0m     )\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 585\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    595\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\bert\\modeling_bert.py:472\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    462\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m ):\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    471\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\bert\\modeling_bert.py:402\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    394\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    400\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    401\u001b[0m ):\n\u001b[1;32m--> 402\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    411\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    412\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\bert\\modeling_bert.py:340\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    338\u001b[0m     attention_probs \u001b[38;5;241m=\u001b[39m attention_probs \u001b[38;5;241m*\u001b[39m head_mask\n\u001b[1;32m--> 340\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m context_layer\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    343\u001b[0m new_context_layer_shape \u001b[38;5;241m=\u001b[39m context_layer\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size,)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 1.20 GiB already allocated; 0 bytes free; 1.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # Show details \n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(\"-\" * 10)\n",
    "    \n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(df_train)\n",
    "    )\n",
    "    \n",
    "    print(f\"Train loss {train_loss} accuracy {train_acc}\")\n",
    "    \n",
    "    # Get model performance (accuracy and loss)\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_data_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(df_val)\n",
    "    )\n",
    "    \n",
    "    print(f\"Val   loss {val_loss} accuracy {val_acc}\")\n",
    "    print()\n",
    "    \n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    # If we beat prev performance\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "        best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853fa546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bad86e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
